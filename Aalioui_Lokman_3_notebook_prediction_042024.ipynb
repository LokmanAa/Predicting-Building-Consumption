{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"C4\"> Projet 4-3 : Variable Cible SiteEnergyUse(kBtu)</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"C4\"> Mise en Place de l'Environnement de Travail</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous commençons par configurer notre environnement de travail en important les librairies nécessaires."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Installation des Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des librairies nécessaires pour le projet\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns  \n",
    "from scipy import stats  \n",
    "import missingno as msno\n",
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import f_oneway\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import shapiro\n",
    "from scipy.stats import normaltest\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats.mstats import winsorize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.stats import t\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Afficher les graphiques directement dans le notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Configuration de Seaborn pour améliorer l'esthétique des graphiques\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Afficher plus de lignes et de colonnes\n",
    "pd.set_option('display.max_row',1000)\n",
    "pd.set_option('display.max_column',300)\n",
    "\n",
    "# Indication d'importations réussies\n",
    "print(\"Librairies importées avec succès !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Version des librairies utilisées\")\n",
    "print(\"--------------------------------\")\n",
    "print(\"Version de Pandas:\", pd.__version__)\n",
    "print(\"Version de NumPy:\", np.__version__)\n",
    "print(\"Version de Matplotlib:\", plt.matplotlib.__version__)\n",
    "print(\"Version de Seaborn:\", sns.__version__)\n",
    "print(\"Version de Missingno:\", msno.__version__)\n",
    "print(\"Version de Statsmodels:\", sm.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lecture des fichiers de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous lisons ensuite les fichiers de données issus du site de seattle.gov."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des fichiers CSV dans des DataFrames pandas\n",
    "data = pd.read_csv('data.csv', delimiter=';')\n",
    "data_bis = pd.read_csv('data.csv', delimiter=';')\n",
    "# Indication d'importations réussies\n",
    "print(\"Fichier importé avec succès !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"C4\"> Modélisation </a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remplacer les valeurs manquantes dans SecondLargestPropertyUseType par \"None\"\n",
    "data['SecondLargestPropertyUseType'].fillna(\"None\", inplace=True)\n",
    "\n",
    "# Remplacer les valeurs manquantes dans SecondLargestPropertyUseTypeGFA par 0\n",
    "data['SecondLargestPropertyUseTypeGFA'].fillna(0, inplace=True)\n",
    "\n",
    "# Remplacer les valeurs manquantes dans ThirdLargestPropertyUseType par \"None\"\n",
    "data['ThirdLargestPropertyUseType'].fillna(\"None\", inplace=True)\n",
    "\n",
    "# Remplacer les valeurs manquantes dans ThirdLargestPropertyUseTypeGFA par 0\n",
    "data['ThirdLargestPropertyUseTypeGFA'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='skyblue'> Préparation des données d'entrainement et de test</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['OSEBuildingID', 'PropertyName', 'Address','Unnamed: 0','CouncilDistrictCode',\n",
    "                   'TaxParcelIdentificationNumber','YearBuilt','ListOfAllPropertyUseTypes',\n",
    "                   'SecondLargestPropertyUseType', 'ThirdLargestPropertyUseType', 'PrimaryPropertyType',\n",
    "                   'CouncilDistrictCode','YearBuilt','PropertyGFABuilding(s)',\n",
    "                   'LargestPropertyUseTypeGFA','SecondLargestPropertyUseTypeGFA', 'ThirdLargestPropertyUseTypeGFA',\n",
    "                    'ENERGYSTARScore', 'SiteEUI(kBtu/sf)', 'SiteEUIWN(kBtu/sf)','SiteEnergyUseWN(kBtu)', 'SteamUse(kBtu)', \n",
    "                    'Electricity(kWh)', 'NaturalGas(therms)',\n",
    "                    'GHGEmissionsIntensity','SourceEUI(kBtu/sf)', 'SourceEUIWN(kBtu/sf)','LargestPropertyUseType',\n",
    "                    'BuildingType','PropertyGFAParking']\n",
    "data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_data = ['Category', 'Neighborhood']\n",
    "numerical_data = ['NumberofFloors','NumberofBuildings','PropertyGFATotal','BuildingAge','GasUseRatio','ElectricityUseRatio','ParkingGFARatio']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='skyblue'> Division des données et entrainement </font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['TotalGHGEmissions','SiteEnergyUse(kBtu)'], axis=1)\n",
    "\n",
    "y = data[['TotalGHGEmissions','SiteEnergyUse(kBtu)']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\n",
    "\n",
    "print('X_train :', X_train.shape)\n",
    "print('y_train :', y_train.shape)\n",
    "print('X_test :' , X_test.shape)\n",
    "print('y_test :',y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='skyblue'> Régression linéaire </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sans Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline de transformations\n",
    "numerical_pipeline = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "categorical_pipeline = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "preprocessor = ColumnTransformer(transformers=[('numerical', numerical_pipeline, numerical_data),\n",
    "                                               ('categorical', categorical_pipeline, categorical_data)])\n",
    "\n",
    "# Pipeline de regression linéaire\n",
    "linear_pipeline = Pipeline([('preprocessor', preprocessor),\n",
    "                            ('linear_regression', LinearRegression())])\n",
    "\n",
    "# Création des métriques de score personnalisées pour R2 MAE RMSE\n",
    "scorer_r2 = make_scorer(r2_score)\n",
    "scorer_mae = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "scorer_rmse = make_scorer(lambda y_true, y_pred: mean_squared_error(y_true, y_pred, squared=False), greater_is_better=False)\n",
    "\n",
    "# Hyperparamètres à rechercher\n",
    "linear_param_grid = {}\n",
    "linear_grid_search = GridSearchCV(linear_pipeline, \n",
    "                                  param_grid=linear_param_grid, \n",
    "                                  cv=5, \n",
    "                                  scoring={'r2': scorer_r2, 'neg_mean_absolute_error': scorer_mae, 'neg_mean_squared_error': scorer_rmse}, \n",
    "                                  refit='r2', \n",
    "                                  n_jobs=-1)\n",
    "\n",
    "# Exécution de la recherche sur la grille des hyperparamètres\n",
    "linear_grid_search.fit(X_train, y_train['SiteEnergyUse(kBtu)'])\n",
    "\n",
    "# Score R2 MAE RMSE\n",
    "best_r2_score = linear_grid_search.best_score_\n",
    "best_mae_score = -linear_grid_search.cv_results_['mean_test_neg_mean_absolute_error'][linear_grid_search.best_index_]\n",
    "best_rmse_score = -linear_grid_search.cv_results_['mean_test_neg_mean_squared_error'][linear_grid_search.best_index_]\n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"Régression linéaire\")\n",
    "print(\"-------------------\")\n",
    "print(\"- Meilleurs hyperparamètres:\", linear_grid_search.best_params_)\n",
    "print(\"- Meilleur score R2 :\", best_r2_score)\n",
    "print(\"- Meilleur score MAE :\", best_mae_score)\n",
    "print(\"- Meilleur score RMSE :\", best_rmse_score)\n",
    "print(\"- Meilleur temps d'execution:\", linear_grid_search.refit_time_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_result=pd.DataFrame(linear_grid_search.cv_results_)\n",
    "cv_result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Avec transformation logarithmique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir la fonction de transformation logarithmique\n",
    "def logarithmic_transform(X): return np.log1p(X)\n",
    "\n",
    "# Pipeline de transformations\n",
    "numerical_pipeline = Pipeline(steps=[('log_transform', FunctionTransformer(func=logarithmic_transform))])\n",
    "categorical_pipeline = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "preprocessor = ColumnTransformer(transformers=[('numerical', numerical_pipeline, numerical_data),\n",
    "                                               ('categorical', categorical_pipeline, categorical_data)])\n",
    "\n",
    "# Pipeline de regression linéaire\n",
    "linear_pipeline = Pipeline([('preprocessor', preprocessor),\n",
    "                            ('linear_regression', LinearRegression())])\n",
    "\n",
    "# Création des métriques de score personnalisées pour R2 MAE RMSE\n",
    "scorer_r2 = make_scorer(r2_score)\n",
    "scorer_mae = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "scorer_rmse = make_scorer(lambda y_true, y_pred: mean_squared_error(y_true, y_pred, squared=False), greater_is_better=False)\n",
    "\n",
    "# Hyperparamètres à rechercher\n",
    "linear_param_grid = {}\n",
    "linear_grid_search = GridSearchCV(linear_pipeline, \n",
    "                                  param_grid=linear_param_grid, \n",
    "                                  cv=5, \n",
    "                                  scoring={'r2': scorer_r2, 'neg_mean_absolute_error': scorer_mae, 'neg_mean_squared_error': scorer_rmse}, \n",
    "                                  refit='r2', \n",
    "                                  n_jobs=-1)\n",
    "\n",
    "# Exécution de la recherche sur la grille des hyperparamètres\n",
    "linear_grid_search.fit(X_train, y_train['SiteEnergyUse(kBtu)'])\n",
    "\n",
    "# Score R2 MAE RMSE\n",
    "best_r2_score = linear_grid_search.best_score_\n",
    "best_mae_score = -linear_grid_search.cv_results_['mean_test_neg_mean_absolute_error'][linear_grid_search.best_index_]\n",
    "best_rmse_score = -linear_grid_search.cv_results_['mean_test_neg_mean_squared_error'][linear_grid_search.best_index_]\n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"Régression linéaire logarithmique\")\n",
    "print(\"-------------------\")\n",
    "print(\"- Meilleurs hyperparamètres:\", linear_grid_search.best_params_)\n",
    "print(\"- Meilleur score R2 :\", best_r2_score)\n",
    "print(\"- Meilleur score MAE :\", best_mae_score)\n",
    "print(\"- Meilleur score RMSE :\", best_rmse_score)\n",
    "print(\"- Meilleur temps d'execution:\", linear_grid_search.refit_time_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='skyblue'> Dummy Regressor </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sans Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline de transformations\n",
    "numerical_pipeline = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "categorical_pipeline = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "preprocessor = ColumnTransformer(transformers=[('numerical', numerical_pipeline, numerical_data),\n",
    "                                               ('categorical', categorical_pipeline, categorical_data)])\n",
    "\n",
    "# Pipeline de régression dummy\n",
    "dummy_pipeline = Pipeline([('preprocessor', preprocessor),\n",
    "                           ('dummy_regressor', DummyRegressor())])\n",
    "\n",
    "# Création des métriques de score personnalisées pour R2 MAE RMSE\n",
    "scorer_r2 = make_scorer(r2_score)\n",
    "scorer_mae = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "scorer_rmse = make_scorer(lambda y_true, y_pred: mean_squared_error(y_true, y_pred, squared=False), greater_is_better=False)\n",
    "\n",
    "# Hyperparamètres à rechercher\n",
    "dummy_param_grid = {'dummy_regressor__strategy': ['mean', 'median', 'quantile'],\n",
    "                    'dummy_regressor__quantile': [0.25, 0.5, 0.75]}\n",
    "dummy_grid_search = GridSearchCV(dummy_pipeline, \n",
    "                                  param_grid=dummy_param_grid, \n",
    "                                  cv=5, \n",
    "                                  scoring={'r2': scorer_r2, 'neg_mean_absolute_error': scorer_mae, 'neg_mean_squared_error': scorer_rmse}, \n",
    "                                  refit='r2', \n",
    "                                  n_jobs=-1)\n",
    "\n",
    "# Exécution de la recherche sur la grille des hyperparamètres\n",
    "dummy_grid_search.fit(X_train, y_train['SiteEnergyUse(kBtu)'])\n",
    "\n",
    "# Score R2 MAE RMSE\n",
    "best_r2_score = dummy_grid_search.best_score_\n",
    "best_mae_score = -dummy_grid_search.cv_results_['mean_test_neg_mean_absolute_error'][dummy_grid_search.best_index_]\n",
    "best_rmse_score = -dummy_grid_search.cv_results_['mean_test_neg_mean_squared_error'][dummy_grid_search.best_index_]\n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"Dummy Regressor\")\n",
    "print(\"-------------------\")\n",
    "print(\"- Meilleurs hyperparamètres:\", dummy_grid_search.best_params_)\n",
    "print(\"- Meilleur score R2 :\", best_r2_score)\n",
    "print(\"- Meilleur score MAE :\", best_mae_score)\n",
    "print(\"- Meilleur score RMSE :\", best_rmse_score)\n",
    "print(\"- Meilleur temps d'execution:\", dummy_grid_search.refit_time_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Avec transformation logarithmique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir la fonction de transformation logarithmique\n",
    "def logarithmic_transform(X): return np.log1p(X)\n",
    "\n",
    "# Pipeline de transformations\n",
    "numerical_pipeline = Pipeline(steps=[('log_transform', FunctionTransformer(func=logarithmic_transform))])\n",
    "categorical_pipeline = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "preprocessor = ColumnTransformer(transformers=[('numerical', numerical_pipeline, numerical_data),\n",
    "                                               ('categorical', categorical_pipeline, categorical_data)])\n",
    "\n",
    "# Pipeline de régression dummy\n",
    "dummy_pipeline = Pipeline([('preprocessor', preprocessor),\n",
    "                           ('dummy_regressor', DummyRegressor())])\n",
    "\n",
    "# Création des métriques de score personnalisées pour R2 MAE RMSE\n",
    "scorer_r2 = make_scorer(r2_score)\n",
    "scorer_mae = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "scorer_rmse = make_scorer(lambda y_true, y_pred: mean_squared_error(y_true, y_pred, squared=False), greater_is_better=False)\n",
    "\n",
    "# Hyperparamètres à rechercher\n",
    "dummy_param_grid = {'dummy_regressor__strategy': ['mean', 'median', 'quantile'],\n",
    "                    'dummy_regressor__quantile': [0.25, 0.5, 0.75]}\n",
    "dummy_grid_search = GridSearchCV(dummy_pipeline, \n",
    "                                  param_grid=dummy_param_grid, \n",
    "                                  cv=5, \n",
    "                                  scoring={'r2': scorer_r2, 'neg_mean_absolute_error': scorer_mae, 'neg_mean_squared_error': scorer_rmse}, \n",
    "                                  refit='r2', \n",
    "                                  n_jobs=-1)\n",
    "\n",
    "# Exécution de la recherche sur la grille des hyperparamètres\n",
    "dummy_grid_search.fit(X_train, y_train['SiteEnergyUse(kBtu)'])\n",
    "\n",
    "# Score R2 MAE RMSE\n",
    "best_r2_score = dummy_grid_search.best_score_\n",
    "best_mae_score = -dummy_grid_search.cv_results_['mean_test_neg_mean_absolute_error'][dummy_grid_search.best_index_]\n",
    "best_rmse_score = -dummy_grid_search.cv_results_['mean_test_neg_mean_squared_error'][dummy_grid_search.best_index_]\n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"Dummy Regressor\")\n",
    "print(\"-------------------\")\n",
    "print(\"- Meilleurs hyperparamètres:\", dummy_grid_search.best_params_)\n",
    "print(\"- Meilleur score R2 :\", best_r2_score)\n",
    "print(\"- Meilleur score MAE :\", best_mae_score)\n",
    "print(\"- Meilleur score RMSE :\", best_rmse_score)\n",
    "print(\"- Meilleur temps d'execution:\", dummy_grid_search.refit_time_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='skyblue'> Régression Lasso </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sans Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline de transformations\n",
    "numerical_pipeline = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "categorical_pipeline = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "preprocessor = ColumnTransformer(transformers=[('numerical', numerical_pipeline, numerical_data),\n",
    "                                               ('categorical', categorical_pipeline, categorical_data)])\n",
    "\n",
    "# Pipeline de régression lasso\n",
    "lasso_pipeline  = Pipeline([('preprocessor', preprocessor),\n",
    "                           ('lasso_regression', Lasso())])\n",
    "\n",
    "# Création des métriques de score personnalisées pour R2 MAE RMSE\n",
    "scorer_r2 = make_scorer(r2_score)\n",
    "scorer_mae = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "scorer_rmse = make_scorer(lambda y_true, y_pred: mean_squared_error(y_true, y_pred, squared=False), greater_is_better=False)\n",
    "\n",
    "# Hyperparamètres à rechercher\n",
    "lasso_param_grid = {\"lasso_regression__alpha\": [0.1, 1.0, 10.0],\n",
    "                    \"lasso_regression__fit_intercept\": [True, False]}\n",
    "lasso_grid_search = GridSearchCV(lasso_pipeline , \n",
    "                                  param_grid=lasso_param_grid, \n",
    "                                  cv=5, \n",
    "                                  scoring={'r2': scorer_r2, 'neg_mean_absolute_error': scorer_mae, 'neg_mean_squared_error': scorer_rmse}, \n",
    "                                  refit='r2', \n",
    "                                  n_jobs=-1)\n",
    "\n",
    "# Exécution de la recherche sur la grille des hyperparamètres\n",
    "lasso_grid_search.fit(X_train, y_train['SiteEnergyUse(kBtu)'])\n",
    "\n",
    "# Score R2 MAE RMSE\n",
    "best_r2_score = lasso_grid_search.best_score_\n",
    "best_mae_score = -lasso_grid_search.cv_results_['mean_test_neg_mean_absolute_error'][lasso_grid_search.best_index_]\n",
    "best_rmse_score = -lasso_grid_search.cv_results_['mean_test_neg_mean_squared_error'][lasso_grid_search.best_index_]\n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"Régression Lasso\")\n",
    "print(\"-------------------\")\n",
    "print(\"- Meilleurs hyperparamètres:\", lasso_grid_search.best_params_)\n",
    "print(\"- Meilleur score R2 :\", best_r2_score)\n",
    "print(\"- Meilleur score MAE :\", best_mae_score)\n",
    "print(\"- Meilleur score RMSE :\", best_rmse_score)\n",
    "print(\"- Meilleur temps d'execution:\", lasso_grid_search.refit_time_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Avec transformation logarithmique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir la fonction de transformation logarithmique\n",
    "def logarithmic_transform(X): return np.log1p(X)\n",
    "\n",
    "# Pipeline de transformations\n",
    "numerical_pipeline = Pipeline(steps=[('log_transform', FunctionTransformer(func=logarithmic_transform))])\n",
    "categorical_pipeline = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "preprocessor = ColumnTransformer(transformers=[('numerical', numerical_pipeline, numerical_data),\n",
    "                                               ('categorical', categorical_pipeline, categorical_data)])\n",
    "\n",
    "# Pipeline de régression lasso\n",
    "lasso_pipeline  = Pipeline([('preprocessor', preprocessor),\n",
    "                           ('lasso_regression', Lasso())])\n",
    "\n",
    "# Création des métriques de score personnalisées pour R2 MAE RMSE\n",
    "scorer_r2 = make_scorer(r2_score)\n",
    "scorer_mae = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "scorer_rmse = make_scorer(lambda y_true, y_pred: mean_squared_error(y_true, y_pred, squared=False), greater_is_better=False)\n",
    "\n",
    "# Hyperparamètres à rechercher\n",
    "lasso_param_grid = {\"lasso_regression__alpha\": [0.1, 1.0, 10.0],\n",
    "                    \"lasso_regression__fit_intercept\": [True, False]}\n",
    "lasso_grid_search = GridSearchCV(lasso_pipeline , \n",
    "                                  param_grid=lasso_param_grid, \n",
    "                                  cv=5, \n",
    "                                  scoring={'r2': scorer_r2, 'neg_mean_absolute_error': scorer_mae, 'neg_mean_squared_error': scorer_rmse}, \n",
    "                                  refit='r2', \n",
    "                                  n_jobs=-1)\n",
    "\n",
    "# Exécution de la recherche sur la grille des hyperparamètres\n",
    "lasso_grid_search.fit(X_train, y_train['SiteEnergyUse(kBtu)'])\n",
    "\n",
    "# Score R2 MAE RMSE\n",
    "best_r2_score = lasso_grid_search.best_score_\n",
    "best_mae_score = -lasso_grid_search.cv_results_['mean_test_neg_mean_absolute_error'][lasso_grid_search.best_index_]\n",
    "best_rmse_score = -lasso_grid_search.cv_results_['mean_test_neg_mean_squared_error'][lasso_grid_search.best_index_]\n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"Régression Lasso\")\n",
    "print(\"-------------------\")\n",
    "print(\"- Meilleurs hyperparamètres:\", lasso_grid_search.best_params_)\n",
    "print(\"- Meilleur score R2 :\", best_r2_score)\n",
    "print(\"- Meilleur score MAE :\", best_mae_score)\n",
    "print(\"- Meilleur score RMSE :\", best_rmse_score)\n",
    "print(\"- Meilleur temps d'execution:\", lasso_grid_search.refit_time_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='skyblue'> Régression Ridge </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sans Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline de transformations\n",
    "numerical_pipeline = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "categorical_pipeline = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "preprocessor = ColumnTransformer(transformers=[('numerical', numerical_pipeline, numerical_data),\n",
    "                                               ('categorical', categorical_pipeline, categorical_data)])\n",
    "\n",
    "# Pipeline de régression Ridge\n",
    "ridge_pipeline = Pipeline([('preprocessor', preprocessor),\n",
    "                           ('ridge_regression', Ridge())])\n",
    "\n",
    "# Création des métriques de score personnalisées pour R2 MAE RMSE\n",
    "scorer_r2 = make_scorer(r2_score)\n",
    "scorer_mae = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "scorer_rmse = make_scorer(lambda y_true, y_pred: mean_squared_error(y_true, y_pred, squared=False), greater_is_better=False)\n",
    "\n",
    "# Hyperparamètres à rechercher\n",
    "ridge_param_grid = {\"ridge_regression__alpha\": [0.1, 1.0, 10.0],\n",
    "                    \"ridge_regression__fit_intercept\": [True, False]}\n",
    "ridge_grid_search = GridSearchCV(ridge_pipeline , \n",
    "                                  param_grid=ridge_param_grid, \n",
    "                                  cv=5, \n",
    "                                  scoring={'r2': scorer_r2, 'neg_mean_absolute_error': scorer_mae, 'neg_mean_squared_error': scorer_rmse}, \n",
    "                                  refit='r2', \n",
    "                                  n_jobs=-1)\n",
    "\n",
    "# Exécution de la recherche sur la grille des hyperparamètres\n",
    "ridge_grid_search.fit(X_train, y_train['SiteEnergyUse(kBtu)'])\n",
    "\n",
    "# Score R2 MAE RMSE\n",
    "best_r2_score = ridge_grid_search.best_score_\n",
    "best_mae_score = -ridge_grid_search.cv_results_['mean_test_neg_mean_absolute_error'][ridge_grid_search.best_index_]\n",
    "best_rmse_score = -ridge_grid_search.cv_results_['mean_test_neg_mean_squared_error'][ridge_grid_search.best_index_]\n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"Régression Ridge\")\n",
    "print(\"-------------------\")\n",
    "print(\"- Meilleurs hyperparamètres:\", ridge_grid_search.best_params_)\n",
    "print(\"- Meilleur score R2 :\", best_r2_score)\n",
    "print(\"- Meilleur score MAE :\", best_mae_score)\n",
    "print(\"- Meilleur score RMSE :\", best_rmse_score)\n",
    "print(\"- Meilleur temps d'execution:\", ridge_grid_search.refit_time_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Avec transformation logarithmique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir la fonction de transformation logarithmique\n",
    "def logarithmic_transform(X): return np.log1p(X)\n",
    "\n",
    "# Pipeline de transformations\n",
    "numerical_pipeline = Pipeline(steps=[('log_transform', FunctionTransformer(func=logarithmic_transform))])\n",
    "categorical_pipeline = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "preprocessor = ColumnTransformer(transformers=[('numerical', numerical_pipeline, numerical_data),\n",
    "                                               ('categorical', categorical_pipeline, categorical_data)])\n",
    "\n",
    "# Pipeline de régression Ridge\n",
    "ridge_pipeline = Pipeline([('preprocessor', preprocessor),\n",
    "                           ('ridge_regression', Ridge())])\n",
    "\n",
    "# Création des métriques de score personnalisées pour R2 MAE RMSE\n",
    "scorer_r2 = make_scorer(r2_score)\n",
    "scorer_mae = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "scorer_rmse = make_scorer(lambda y_true, y_pred: mean_squared_error(y_true, y_pred, squared=False), greater_is_better=False)\n",
    "\n",
    "# Hyperparamètres à rechercher\n",
    "ridge_param_grid = {\"ridge_regression__alpha\": [0.1, 1.0, 10.0],\n",
    "                    \"ridge_regression__fit_intercept\": [True, False]}\n",
    "ridge_grid_search = GridSearchCV(ridge_pipeline , \n",
    "                                  param_grid=ridge_param_grid, \n",
    "                                  cv=5, \n",
    "                                  scoring={'r2': scorer_r2, 'neg_mean_absolute_error': scorer_mae, 'neg_mean_squared_error': scorer_rmse}, \n",
    "                                  refit='r2', \n",
    "                                  n_jobs=-1)\n",
    "\n",
    "# Exécution de la recherche sur la grille des hyperparamètres\n",
    "ridge_grid_search.fit(X_train, y_train['SiteEnergyUse(kBtu)'])\n",
    "\n",
    "# Score R2 MAE RMSE\n",
    "best_r2_score = ridge_grid_search.best_score_\n",
    "best_mae_score = -ridge_grid_search.cv_results_['mean_test_neg_mean_absolute_error'][ridge_grid_search.best_index_]\n",
    "best_rmse_score = -ridge_grid_search.cv_results_['mean_test_neg_mean_squared_error'][ridge_grid_search.best_index_]\n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"Régression Ridge\")\n",
    "print(\"-------------------\")\n",
    "print(\"- Meilleurs hyperparamètres:\", ridge_grid_search.best_params_)\n",
    "print(\"- Meilleur score R2 :\", best_r2_score)\n",
    "print(\"- Meilleur score MAE :\", best_mae_score)\n",
    "print(\"- Meilleur score RMSE :\", best_rmse_score)\n",
    "print(\"- Meilleur temps d'execution:\", ridge_grid_search.refit_time_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='skyblue'> Random Forest </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sans Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline de transformations\n",
    "numerical_pipeline = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "categorical_pipeline = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "preprocessor = ColumnTransformer(transformers=[('numerical', numerical_pipeline, numerical_data),\n",
    "                                               ('categorical', categorical_pipeline, categorical_data)])\n",
    "\n",
    "# Pipeline de Random Forest\n",
    "forest_pipeline = Pipeline([('preprocessor', preprocessor),\n",
    "                            ('random_forest', RandomForestRegressor())])\n",
    "\n",
    "# Création des métriques de score personnalisées pour R2 MAE RMSE\n",
    "scorer_r2 = make_scorer(r2_score)\n",
    "scorer_mae = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "scorer_rmse = make_scorer(lambda y_true, y_pred: mean_squared_error(y_true, y_pred, squared=False), greater_is_better=False)\n",
    "\n",
    "# Hyperparamètres à rechercher\n",
    "forest_param_grid = {'random_forest__max_features' : [0.8],\n",
    "                    'random_forest__max_depth': [5, 10, 15],\n",
    "                    'random_forest__min_samples_split': [2, 5, 10],\n",
    "                    'random_forest__bootstrap' : [True, False],\n",
    "                    'random_forest__min_samples_leaf': [1,2,5,10]}\n",
    "forest_grid_search = GridSearchCV(forest_pipeline, \n",
    "                                  param_grid=forest_param_grid, \n",
    "                                  cv=5, \n",
    "                                  scoring={'r2': scorer_r2, 'neg_mean_absolute_error': scorer_mae, 'neg_mean_squared_error': scorer_rmse}, \n",
    "                                  refit='r2', \n",
    "                                  n_jobs=-1)\n",
    "\n",
    "# Exécution de la recherche sur la grille des hyperparamètres\n",
    "forest_grid_search.fit(X_train, y_train['SiteEnergyUse(kBtu)'])\n",
    "\n",
    "# Score R2 MAE RMSE\n",
    "best_r2_score = forest_grid_search.best_score_\n",
    "best_mae_score = -forest_grid_search.cv_results_['mean_test_neg_mean_absolute_error'][forest_grid_search.best_index_]\n",
    "best_rmse_score = -forest_grid_search.cv_results_['mean_test_neg_mean_squared_error'][forest_grid_search.best_index_]\n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"Random Forest\")\n",
    "print(\"-------------------\")\n",
    "print(\"- Meilleurs hyperparamètres:\", forest_grid_search.best_params_)\n",
    "print(\"- Meilleur score R2 :\", best_r2_score)\n",
    "print(\"- Meilleur score MAE :\", best_mae_score)\n",
    "print(\"- Meilleur score RMSE :\", best_rmse_score)\n",
    "print(\"- Meilleur temps d'execution:\", forest_grid_search.refit_time_  )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Avec transformation logarithmique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir la fonction de transformation logarithmique\n",
    "def logarithmic_transform(X): return np.log1p(X)\n",
    "\n",
    "# Pipeline de transformations\n",
    "numerical_pipeline = Pipeline(steps=[('log_transform', FunctionTransformer(func=logarithmic_transform))])\n",
    "categorical_pipeline = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "preprocessor = ColumnTransformer(transformers=[('numerical', numerical_pipeline, numerical_data),\n",
    "                                               ('categorical', categorical_pipeline, categorical_data)])\n",
    "\n",
    "# Pipeline de Random Forest\n",
    "forest_pipeline = Pipeline([('preprocessor', preprocessor),\n",
    "                            ('random_forest', RandomForestRegressor())])\n",
    "\n",
    "# Création des métriques de score personnalisées pour R2 MAE RMSE\n",
    "scorer_r2 = make_scorer(r2_score)\n",
    "scorer_mae = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "scorer_rmse = make_scorer(lambda y_true, y_pred: mean_squared_error(y_true, y_pred, squared=False), greater_is_better=False)\n",
    "\n",
    "# Hyperparamètres à rechercher\n",
    "forest_param_grid = {'random_forest__max_features' : [0.8],\n",
    "                    'random_forest__max_depth': [5, 10, 15],\n",
    "                    'random_forest__min_samples_split': [2, 5, 10],\n",
    "                    'random_forest__bootstrap' : [True, False],\n",
    "                    'random_forest__min_samples_leaf': [1,2,5,10]}\n",
    "\n",
    "forest_grid_search = GridSearchCV(forest_pipeline, \n",
    "                                  param_grid=forest_param_grid, \n",
    "                                  cv=5, \n",
    "                                  scoring={'r2': scorer_r2, 'neg_mean_absolute_error': scorer_mae, 'neg_mean_squared_error': scorer_rmse}, \n",
    "                                  refit='r2', \n",
    "                                  n_jobs=-1)\n",
    "\n",
    "# Exécution de la recherche sur la grille des hyperparamètres\n",
    "forest_grid_search.fit(X_train, y_train['SiteEnergyUse(kBtu)'])\n",
    "\n",
    "# Score R2 MAE RMSE\n",
    "best_r2_score = forest_grid_search.best_score_\n",
    "best_mae_score = -forest_grid_search.cv_results_['mean_test_neg_mean_absolute_error'][forest_grid_search.best_index_]\n",
    "best_rmse_score = -forest_grid_search.cv_results_['mean_test_neg_mean_squared_error'][forest_grid_search.best_index_]\n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"Random Forest\")\n",
    "print(\"-------------------\")\n",
    "print(\"- Meilleurs hyperparamètres:\", forest_grid_search.best_params_)\n",
    "print(\"- Meilleur score R2 :\", best_r2_score)\n",
    "print(\"- Meilleur score MAE :\", best_mae_score)\n",
    "print(\"- Meilleur score RMSE :\", best_rmse_score)\n",
    "print(\"- Meilleur temps d'execution:\", forest_grid_search.refit_time_  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='skyblue'> Bagging Regressor</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sans Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline de transformations\n",
    "numerical_pipeline = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "categorical_pipeline = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "preprocessor = ColumnTransformer(transformers=[('numerical', numerical_pipeline, numerical_data),\n",
    "                                               ('categorical', categorical_pipeline, categorical_data)])\n",
    "\n",
    "# Pipeline de Bagging\n",
    "bagging_pipeline = Pipeline([('preprocessor', preprocessor),\n",
    "                             ('bagging', BaggingRegressor())])\n",
    "\n",
    "# Création des métriques de score personnalisées pour R2 MAE RMSE\n",
    "scorer_r2 = make_scorer(r2_score)\n",
    "scorer_mae = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "scorer_rmse = make_scorer(lambda y_true, y_pred: mean_squared_error(y_true, y_pred, squared=False), greater_is_better=False)\n",
    "\n",
    "# Hyperparamètres à rechercher\n",
    "bagging_param_grid = {'bagging__n_estimators': [10, 50],  \n",
    "                     'bagging__max_samples': [0.5, 0.7], \n",
    "                     'bagging__max_features': [0.5, 0.7],\n",
    "                     'bagging__bootstrap': [True, False]}\n",
    "\n",
    "bagging_grid_search = GridSearchCV(bagging_pipeline, \n",
    "                                   param_grid=bagging_param_grid, \n",
    "                                   cv=5, \n",
    "                                   scoring={'r2': scorer_r2, 'neg_mean_absolute_error': scorer_mae, 'neg_mean_squared_error': scorer_rmse}, \n",
    "                                   refit='r2', \n",
    "                                   n_jobs=-1)\n",
    "\n",
    "# Exécution de la recherche sur la grille des hyperparamètres\n",
    "bagging_grid_search.fit(X_train, y_train['SiteEnergyUse(kBtu)'])\n",
    "\n",
    "# Score R2 MAE RMSE\n",
    "best_r2_score = bagging_grid_search.best_score_\n",
    "best_mae_score = -bagging_grid_search.cv_results_['mean_test_neg_mean_absolute_error'][bagging_grid_search.best_index_]\n",
    "best_rmse_score = -bagging_grid_search.cv_results_['mean_test_neg_mean_squared_error'][bagging_grid_search.best_index_]\n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"Bagging Regressor\")\n",
    "print(\"-------------------\")\n",
    "print(\"- Meilleurs hyperparamètres:\", bagging_grid_search.best_params_)\n",
    "print(\"- Meilleur score R2 :\", best_r2_score)\n",
    "print(\"- Meilleur score MAE :\", best_mae_score)\n",
    "print(\"- Meilleur score RMSE :\", best_rmse_score)\n",
    "print(\"- Meilleur temps d'execution:\", bagging_grid_search.refit_time_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Avec transformation logarithmique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir la fonction de transformation logarithmique\n",
    "def logarithmic_transform(X): return np.log1p(X)\n",
    "\n",
    "# Pipeline de transformations\n",
    "numerical_pipeline = Pipeline(steps=[('log_transform', FunctionTransformer(func=logarithmic_transform))])\n",
    "categorical_pipeline = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "preprocessor = ColumnTransformer(transformers=[('numerical', numerical_pipeline, numerical_data),\n",
    "                                               ('categorical', categorical_pipeline, categorical_data)])\n",
    "\n",
    "# Pipeline de Bagging\n",
    "bagging_pipeline = Pipeline([('preprocessor', preprocessor),\n",
    "                             ('bagging', BaggingRegressor())])\n",
    "\n",
    "# Création des métriques de score personnalisées pour R2 MAE RMSE\n",
    "scorer_r2 = make_scorer(r2_score)\n",
    "scorer_mae = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "scorer_rmse = make_scorer(lambda y_true, y_pred: mean_squared_error(y_true, y_pred, squared=False), greater_is_better=False)\n",
    "\n",
    "# Hyperparamètres à rechercher\n",
    "bagging_param_grid = {'bagging__n_estimators': [10, 50],  \n",
    "                     'bagging__max_samples': [0.5, 0.7], \n",
    "                     'bagging__max_features': [0.5, 0.7],\n",
    "                     'bagging__bootstrap': [True, False]}\n",
    "\n",
    "bagging_grid_search = GridSearchCV(bagging_pipeline, \n",
    "                                   param_grid=bagging_param_grid, \n",
    "                                   cv=5, \n",
    "                                   scoring={'r2': scorer_r2, 'neg_mean_absolute_error': scorer_mae, 'neg_mean_squared_error': scorer_rmse}, \n",
    "                                   refit='r2', \n",
    "                                   n_jobs=-1)\n",
    "\n",
    "# Exécution de la recherche sur la grille des hyperparamètres\n",
    "bagging_grid_search.fit(X_train, y_train['SiteEnergyUse(kBtu)'])\n",
    "\n",
    "# Score R2 MAE RMSE\n",
    "best_r2_score = bagging_grid_search.best_score_\n",
    "best_mae_score = -bagging_grid_search.cv_results_['mean_test_neg_mean_absolute_error'][bagging_grid_search.best_index_]\n",
    "best_rmse_score = -bagging_grid_search.cv_results_['mean_test_neg_mean_squared_error'][bagging_grid_search.best_index_]\n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"Bagging Regressor\")\n",
    "print(\"-------------------\")\n",
    "print(\"- Meilleurs hyperparamètres:\", bagging_grid_search.best_params_)\n",
    "print(\"- Meilleur score R2 :\", best_r2_score)\n",
    "print(\"- Meilleur score MAE :\", best_mae_score)\n",
    "print(\"- Meilleur score RMSE :\", best_rmse_score)\n",
    "print(\"- Meilleur temps d'execution:\", bagging_grid_search.refit_time_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='skyblue'> Gradient Boost Regressor</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sans Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline de transformations\n",
    "numerical_pipeline = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "categorical_pipeline = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "preprocessor = ColumnTransformer(transformers=[('numerical', numerical_pipeline, numerical_data),\n",
    "                                               ('categorical', categorical_pipeline, categorical_data)])\n",
    "\n",
    "# Pipeline de Gradient Boosting\n",
    "gb_pipeline = Pipeline([('preprocessor', preprocessor),\n",
    "                        ('gradient_boosting', GradientBoostingRegressor())])\n",
    "\n",
    "# Création des métriques de score personnalisées pour R2 MAE RMSE\n",
    "scorer_r2 = make_scorer(r2_score)\n",
    "scorer_mae = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "scorer_rmse = make_scorer(lambda y_true, y_pred: mean_squared_error(y_true, y_pred, squared=False), greater_is_better=False)\n",
    "\n",
    "# Hyperparamètres à rechercher\n",
    "gb_param_grid = {'gradient_boosting__learning_rate': [0.01, 0.1, 0.5], # Taux d'apprentissage\n",
    "                'gradient_boosting__n_estimators': [50, 100, 200],     # Nombre d'estimateurs (arbres)\n",
    "                 'gradient_boosting__max_depth': [3, 5, 7],            # Profondeur maximale des arbres\n",
    "                 'gradient_boosting__min_samples_split': [2, 5, 10],   # Nombre minimal d'échantillons pour la séparation\n",
    "                 'gradient_boosting__min_samples_leaf': [1, 2, 5]}     # Nombre minimal d'échantillons dans les feuilles\n",
    "\n",
    "gb_grid_search = GridSearchCV(gb_pipeline, \n",
    "                              param_grid=gb_param_grid, \n",
    "                              cv=5, \n",
    "                              scoring={'r2': scorer_r2, 'neg_mean_absolute_error': scorer_mae, 'neg_mean_squared_error': scorer_rmse}, \n",
    "                              refit='r2', \n",
    "                              n_jobs=-1)\n",
    "\n",
    "# Exécution de la recherche sur la grille des hyperparamètres\n",
    "gb_grid_search.fit(X_train, y_train['SiteEnergyUse(kBtu)'])\n",
    "\n",
    "# Score R2 MAE RMSE\n",
    "best_r2_score = gb_grid_search.best_score_\n",
    "best_mae_score = -gb_grid_search.cv_results_['mean_test_neg_mean_absolute_error'][gb_grid_search.best_index_]\n",
    "best_rmse_score = -gb_grid_search.cv_results_['mean_test_neg_mean_squared_error'][gb_grid_search.best_index_]\n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"Gradient Boosting\")\n",
    "print(\"-------------------\")\n",
    "print(\"- Meilleurs hyperparamètres:\", gb_grid_search.best_params_)\n",
    "print(\"- Meilleur score R2 :\", best_r2_score)\n",
    "print(\"- Meilleur score MAE :\", best_mae_score)\n",
    "print(\"- Meilleur score RMSE :\", best_rmse_score)\n",
    "print(\"- Meilleur temps d'execution:\", gb_grid_search.refit_time_  )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Avec transformation logarithmique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir la fonction de transformation logarithmique\n",
    "def logarithmic_transform(X): return np.log1p(X)\n",
    "\n",
    "# Pipeline de transformations\n",
    "numerical_pipeline = Pipeline(steps=[('log_transform', FunctionTransformer(func=logarithmic_transform))])\n",
    "categorical_pipeline = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "preprocessor = ColumnTransformer(transformers=[('numerical', numerical_pipeline, numerical_data),\n",
    "                                               ('categorical', categorical_pipeline, categorical_data)])\n",
    "\n",
    "# Pipeline de Gradient Boosting\n",
    "gb_pipeline = Pipeline([('preprocessor', preprocessor),\n",
    "                        ('gradient_boosting', GradientBoostingRegressor())])\n",
    "\n",
    "# Création des métriques de score personnalisées pour R2 MAE RMSE\n",
    "scorer_r2 = make_scorer(r2_score)\n",
    "scorer_mae = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "scorer_rmse = make_scorer(lambda y_true, y_pred: mean_squared_error(y_true, y_pred, squared=False), greater_is_better=False)\n",
    "\n",
    "# Hyperparamètres à rechercher\n",
    "gb_param_grid = {'gradient_boosting__learning_rate': [0.01, 0.1, 0.5], # Taux d'apprentissage\n",
    "                'gradient_boosting__n_estimators': [50, 100, 200],     # Nombre d'estimateurs (arbres)\n",
    "                 'gradient_boosting__max_depth': [3, 5, 7],            # Profondeur maximale des arbres\n",
    "                 'gradient_boosting__min_samples_split': [2, 5, 10],   # Nombre minimal d'échantillons pour la séparation\n",
    "                 'gradient_boosting__min_samples_leaf': [1, 2, 5]}     # Nombre minimal d'échantillons dans les feuilles\n",
    "\n",
    "gb_grid_search = GridSearchCV(gb_pipeline, \n",
    "                              param_grid=gb_param_grid, \n",
    "                              cv=5, \n",
    "                              scoring={'r2': scorer_r2, 'neg_mean_absolute_error': scorer_mae, 'neg_mean_squared_error': scorer_rmse}, \n",
    "                              refit='r2', \n",
    "                              n_jobs=-1)\n",
    "\n",
    "# Exécution de la recherche sur la grille des hyperparamètres\n",
    "gb_grid_search.fit(X_train, y_train['SiteEnergyUse(kBtu)'])\n",
    "\n",
    "# Score R2 MAE RMSE\n",
    "best_r2_score = gb_grid_search.best_score_\n",
    "best_mae_score = -gb_grid_search.cv_results_['mean_test_neg_mean_absolute_error'][gb_grid_search.best_index_]\n",
    "best_rmse_score = -gb_grid_search.cv_results_['mean_test_neg_mean_squared_error'][gb_grid_search.best_index_]\n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"Gradient Boosting logarithme\")\n",
    "print(\"-------------------\")\n",
    "print(\"- Meilleurs hyperparamètres:\", gb_grid_search.best_params_)\n",
    "print(\"- Meilleur score R2 :\", best_r2_score)\n",
    "print(\"- Meilleur score MAE :\", best_mae_score)\n",
    "print(\"- Meilleur score RMSE :\", best_rmse_score)\n",
    "print(\"- Meilleur temps d'execution:\", gb_grid_search.refit_time_  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='skyblue'> Sélection du meilleur modèle </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sans Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline de transformations\n",
    "numerical_pipeline = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "categorical_pipeline = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "preprocessor = ColumnTransformer(transformers=[('numerical', numerical_pipeline, numerical_data),\n",
    "                                               ('categorical', categorical_pipeline, categorical_data)])\n",
    "\n",
    "# Liste contenant les modèles et leurs hyperparamètres\n",
    "measures = []\n",
    "models_params = [\n",
    "    (LinearRegression(), {}),\n",
    "    (DummyRegressor(), {'model__quantile': [0.75], 'model__strategy': ['quantile']}),\n",
    "    (Lasso(), {'model__alpha': [10.0], 'model__fit_intercept': [True]}),\n",
    "    (Ridge(), {'model__alpha': [10.0], 'model__fit_intercept': [False]}),\n",
    "    (RandomForestRegressor(), {'model__bootstrap': [False], 'model__max_depth': [15], 'model__max_features': [0.8], 'model__min_samples_leaf': [1], 'model__min_samples_split': [2]}),\n",
    "    (BaggingRegressor(), {'model__bootstrap': [False], 'model__max_features': [0.7], 'model__max_samples': [0.5], 'model__n_estimators': [50]}),\n",
    "    (GradientBoostingRegressor(), {'model__learning_rate': [0.01], 'model__max_depth': [3], 'model__min_samples_leaf': [5], 'model__min_samples_split': [2], 'model__n_estimators': [200]})\n",
    "]\n",
    "\n",
    "# Création des métriques de score personnalisées pour R2 MAE RMSE\n",
    "scorer_r2 = make_scorer(r2_score)\n",
    "scorer_mae = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "scorer_rmse = make_scorer(lambda y_true, y_pred: mean_squared_error(y_true, y_pred, squared=False), greater_is_better=False)\n",
    "\n",
    "# Boucle sur chaque modèle\n",
    "for model, params in models_params:\n",
    "    pipeline = Pipeline([('preprocessor', preprocessor), ('model', model)])\n",
    "    grid_search = GridSearchCV(pipeline, params, cv=5, \n",
    "                              scoring={'r2': scorer_r2, 'neg_mean_absolute_error': scorer_mae, 'neg_mean_squared_error': scorer_rmse}, \n",
    "                              refit='r2', \n",
    "                              n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train['SiteEnergyUse(kBtu)'])\n",
    "    \n",
    "    # Score R2 MAE RMSE\n",
    "    best_r2_score = grid_search.best_score_\n",
    "    best_mae_score = -grid_search.cv_results_['mean_test_neg_mean_absolute_error'][grid_search.best_index_]\n",
    "    best_rmse_score = -grid_search.cv_results_['mean_test_neg_mean_squared_error'][grid_search.best_index_]\n",
    "\n",
    "    # Stocker les résultats dans la liste des mesures\n",
    "    measures.append({'Modèle': model.__class__.__name__,\n",
    "                     'Meilleur R²': best_r2_score,\n",
    "                     'Meilleur MAE': best_mae_score,\n",
    "                     'Meilleur RMSE': best_rmse_score,\n",
    "                     'Temps d\\'exécution': grid_search.refit_time_})\n",
    "\n",
    "# Création df et affichage\n",
    "measures_df = pd.DataFrame(measures)\n",
    "measures_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Avec transformation logarithmique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir la fonction de transformation logarithmique\n",
    "def logarithmic_transform(X): return np.log1p(X)\n",
    "\n",
    "# Pipeline de transformations\n",
    "numerical_pipeline = Pipeline(steps=[('log_transform', FunctionTransformer(func=logarithmic_transform))])\n",
    "categorical_pipeline = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "preprocessor = ColumnTransformer(transformers=[('numerical', numerical_pipeline, numerical_data),\n",
    "                                               ('categorical', categorical_pipeline, categorical_data)])\n",
    "\n",
    "# Liste contenant les modèles et leurs hyperparametres\n",
    "measures = []\n",
    "models_params = [(LinearRegression(), {}),\n",
    "    (DummyRegressor(), {'model__quantile': [0.75], 'model__strategy': ['quantile']}),\n",
    "    (Lasso(), {'model__alpha': [10.0], 'model__fit_intercept': [True]}),\n",
    "    (Ridge(), {'model__alpha': [10.0], 'model__fit_intercept': [False]}),\n",
    "    (RandomForestRegressor(), {'model__bootstrap': [False], 'model__max_depth': [15], 'model__max_features': [0.8], 'model__min_samples_leaf': [1], 'model__min_samples_split': [2]}),\n",
    "    (BaggingRegressor(), {'model__bootstrap': [False], 'model__max_features': [0.7], 'model__max_samples': [0.5], 'model__n_estimators': [50]}),\n",
    "    (GradientBoostingRegressor(), {'model__learning_rate': [0.01], 'model__max_depth': [3], 'model__min_samples_leaf': [5], 'model__min_samples_split': [2], 'model__n_estimators': [200]})]\n",
    "\n",
    "# Création des métriques de score personnalisées pour R2 MAE RMSE\n",
    "scorer_r2 = make_scorer(r2_score)\n",
    "scorer_mae = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "scorer_rmse = make_scorer(lambda y_true, y_pred: mean_squared_error(y_true, y_pred, squared=False), greater_is_better=False)\n",
    "\n",
    "# Boucle sur chaque modèle\n",
    "for model, params in models_params:\n",
    "    pipeline = Pipeline([('preprocessor', preprocessor), ('model', model)])\n",
    "    grid_search = GridSearchCV(pipeline, params, cv=5, \n",
    "                              scoring={'r2': scorer_r2, 'neg_mean_absolute_error': scorer_mae, 'neg_mean_squared_error': scorer_rmse}, \n",
    "                              refit='r2', \n",
    "                              n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train['SiteEnergyUse(kBtu)'])\n",
    "    \n",
    "# Score R2 MAE RMSE\n",
    "    best_r2_score = grid_search.best_score_\n",
    "    best_mae_score = -grid_search.cv_results_['mean_test_neg_mean_absolute_error'][grid_search.best_index_]\n",
    "    best_rmse_score = -grid_search.cv_results_['mean_test_neg_mean_squared_error'][grid_search.best_index_]\n",
    "\n",
    "    measures.append({'Modèle': model.__class__.__name__,\n",
    "                'Meilleur R²': best_r2_score,\n",
    "                'Meilleur MAE': best_mae_score,\n",
    "                'Meilleur RMSE': best_rmse_score,\n",
    "                'Temps d\\'exécution': grid_search.refit_time_})\n",
    "\n",
    "# création df et affichage\n",
    "measures_ln_df = pd.DataFrame(measures)\n",
    "measures_ln_df['Modèle'] = measures_ln_df['Modèle'].apply(lambda x: x + '_ln')\n",
    "measures_ln_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concaténation des DataFrames measures_df et measures_ln_df\n",
    "allmeasures_df = pd.concat([measures_ln_df, measures_df])\n",
    "allmeasures_df = allmeasures_df.sort_values(by='Modèle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allmeasures_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Couleurs par pair\n",
    "num_pairs = len(allmeasures_df) // 2\n",
    "color_palette = plt.cm.viridis(np.linspace(0, 1, num_pairs))\n",
    "\n",
    "# Visualisation\n",
    "plt.figure(figsize=(20, 16))\n",
    "\n",
    "# Boucle\n",
    "for i, metric in enumerate(['Meilleur R²', 'Meilleur MAE', 'Meilleur RMSE', 'Temps d\\'exécution']):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    for j in range(0, len(allmeasures_df), 2):\n",
    "        start_idx = j\n",
    "        end_idx = min(j + 1, len(allmeasures_df) - 1)\n",
    "        measures_data_plot = allmeasures_df.iloc[start_idx:end_idx+1]\n",
    "        color_idx = j // 2\n",
    "        color = color_palette[color_idx]\n",
    "        plt.bar(measures_data_plot['Modèle'], measures_data_plot[metric], color=color, label=f'Pair {color_idx + 1}')\n",
    "    plt.title(f'{metric} par Modèle')\n",
    "    plt.xlabel('Modèle')\n",
    "    plt.ylabel(metric)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='skyblue'> Choix du Random Forest Regressor </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exécution de la recherche sur la grille des hyperparamètres\n",
    "forest_grid_search.fit(X_train, y_train['SiteEnergyUse(kBtu)'])\n",
    "\n",
    "# Récupérez le meilleur modèle entraîné\n",
    "best_model = forest_grid_search.best_estimator_\n",
    "\n",
    "# Récupérez les noms des caractéristiques numériques à partir du préprocesseur\n",
    "numerical_feature_names = best_model.named_steps['preprocessor'].transformers_[0][2]\n",
    "\n",
    "# Récupérez les noms des caractéristiques catégorielles encodées\n",
    "categorical_feature_names = best_model.named_steps['preprocessor'].named_transformers_['categorical'].named_steps['onehot'].get_feature_names_out()\n",
    "\n",
    "# Concaténez les noms des caractéristiques catégorielles et numériques\n",
    "feature_names = np.concatenate([numerical_feature_names, categorical_feature_names])\n",
    "\n",
    "# Récupérez l'importance des caractéristiques à partir du meilleur modèle\n",
    "feature_importance = best_model.named_steps['random_forest'].feature_importances_\n",
    "\n",
    "# Créez un DataFrame pour afficher l'importance des caractéristiques\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importance})\n",
    "\n",
    "# Triez les caractéristiques par ordre d'importance décroissante\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "\n",
    "# Visualisez les 10 caractéristiques les plus importantes\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'], color='skyblue')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Caractéristique')\n",
    "plt.title('Top 10 des Caractéristiques les Plus Importantes')\n",
    "plt.gca().invert_yaxis()  # Inverser l'axe y pour avoir les caractéristiques les plus importantes en haut\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir la fonction de transformation logarithmique\n",
    "def logarithmic_transform(X): return np.log1p(X)\n",
    "\n",
    "# Pipeline de transformations\n",
    "numerical_pipeline = Pipeline(steps=[('log_transform', FunctionTransformer(func=logarithmic_transform))])\n",
    "categorical_pipeline = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "preprocessor = ColumnTransformer(transformers=[('numerical', numerical_pipeline, numerical_data),\n",
    "                                               ('categorical', categorical_pipeline, categorical_data)])\n",
    "\n",
    "# Pipeline de Random Forest\n",
    "forest_pipeline = Pipeline([('preprocessor', preprocessor),\n",
    "                            ('random_forest', RandomForestRegressor())])\n",
    "\n",
    "# Calcul des scores à l'aide de la validation croisée\n",
    "cv_scores_r2 = cross_val_score(forest_pipeline, X_train, y_train['SiteEnergyUse(kBtu)'], cv=5, scoring='r2')\n",
    "cv_scores_mae = cross_val_score(forest_pipeline, X_train, y_train['SiteEnergyUse(kBtu)'], cv=5, scoring='neg_mean_absolute_error')\n",
    "cv_scores_rmse = cross_val_score(forest_pipeline, X_train, y_train['SiteEnergyUse(kBtu)'], cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Affichage des scores moyens\n",
    "print(\"R2 moyen:\", np.mean(cv_scores_r2))\n",
    "print(\"MAE moyen:\", -np.mean(cv_scores_mae))\n",
    "print(\"RMSE moyen:\", np.sqrt(-np.mean(cv_scores_rmse)))\n",
    "\n",
    "# Visualisation des scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Score R2\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(cv_scores_r2, marker='o')\n",
    "plt.title('Scores R2')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Score')\n",
    "\n",
    "# Score MAE\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(-cv_scores_mae, marker='o')\n",
    "plt.title('Scores MAE')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Score')\n",
    "\n",
    "# Score RMSE\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(np.sqrt(-cv_scores_rmse), marker='o')\n",
    "plt.title('Scores RMSE')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf_model = forest_grid_search.best_estimator_\n",
    "best_rf_model.fit(X_train, y_train['SiteEnergyUse(kBtu)'])\n",
    "test_predictions = best_rf_model.predict(X_test)\n",
    "\n",
    "# Plotting the Model Predictios vs True Values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test['SiteEnergyUse(kBtu)'], y_test['SiteEnergyUse(kBtu)'], alpha=0.5, color='blue', label='True Values')\n",
    "plt.scatter(y_test['SiteEnergyUse(kBtu)'], test_predictions, alpha=0.5, color='red', label='Model Predictions')\n",
    "plt.title('Valeurs réélles vs prédictions du modèle')\n",
    "plt.xlabel('Valeurs réélles')\n",
    "plt.ylabel('Prédictions')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='skyblue'> Importance de la variable EnergyStarScore </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['OSEBuildingID', 'PropertyName', 'Address','Unnamed: 0','CouncilDistrictCode',\n",
    "                   'TaxParcelIdentificationNumber','YearBuilt','ListOfAllPropertyUseTypes',\n",
    "                   'SecondLargestPropertyUseType', 'ThirdLargestPropertyUseType', 'PrimaryPropertyType',\n",
    "                   'CouncilDistrictCode','YearBuilt','PropertyGFABuilding(s)',\n",
    "                   'LargestPropertyUseTypeGFA','SecondLargestPropertyUseTypeGFA', 'ThirdLargestPropertyUseTypeGFA',\n",
    "                    'SiteEUI(kBtu/sf)', 'SiteEUIWN(kBtu/sf)','SiteEnergyUseWN(kBtu)', 'SteamUse(kBtu)', \n",
    "                    'Electricity(kWh)', 'NaturalGas(therms)',\n",
    "                    'GHGEmissionsIntensity','SourceEUI(kBtu/sf)', 'SourceEUIWN(kBtu/sf)','LargestPropertyUseType',\n",
    "                    'BuildingType','PropertyGFAParking']\n",
    "\n",
    "data_bis.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# Supprimer les lignes contenant des valeurs NaN dans la colonne 'ENERGYSTARScore'\n",
    "data_bis.dropna(subset=['ENERGYSTARScore'], inplace=True)\n",
    "\n",
    "categorical_data = ['Category', 'Neighborhood']\n",
    "numerical_data = ['NumberofFloors','NumberofBuildings','PropertyGFATotal','BuildingAge','GasUseRatio','ElectricityUseRatio','ParkingGFARatio']\n",
    "\n",
    "X = data_bis.drop(['TotalGHGEmissions','SiteEnergyUse(kBtu)'], axis=1)\n",
    "\n",
    "y = data_bis[['TotalGHGEmissions','SiteEnergyUse(kBtu)']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\n",
    "\n",
    "print('X_train :', X_train.shape)\n",
    "print('y_train :', y_train.shape)\n",
    "print('X_test :' , X_test.shape)\n",
    "print('y_test :',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir la fonction de transformation logarithmique\n",
    "def logarithmic_transform(X): return np.log1p(X)\n",
    "\n",
    "# Pipeline de transformations\n",
    "numerical_pipeline = Pipeline(steps=[('log_transform', FunctionTransformer(func=logarithmic_transform))])\n",
    "categorical_pipeline = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "preprocessor = ColumnTransformer(transformers=[('numerical', numerical_pipeline, numerical_data),\n",
    "                                               ('categorical', categorical_pipeline, categorical_data)])\n",
    "\n",
    "# Pipeline de Random Forest\n",
    "forest_pipeline = Pipeline([('preprocessor', preprocessor),\n",
    "                            ('random_forest', RandomForestRegressor())])\n",
    "\n",
    "# Création des métriques de score personnalisées pour R2 MAE RMSE\n",
    "scorer_r2 = make_scorer(r2_score)\n",
    "scorer_mae = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "scorer_rmse = make_scorer(lambda y_true, y_pred: mean_squared_error(y_true, y_pred, squared=False), greater_is_better=False)\n",
    "\n",
    "# Hyperparamètres à rechercher\n",
    "forest_param_grid = {'random_forest__bootstrap': [False], 'random_forest__max_depth': [15], 'random_forest__max_features': [0.8], 'random_forest__min_samples_leaf': [1], 'random_forest__min_samples_split': [2]}\n",
    "\n",
    "forest_grid_search = GridSearchCV(forest_pipeline, \n",
    "                                  param_grid=forest_param_grid, \n",
    "                                  cv=5, \n",
    "                                  scoring={'r2': scorer_r2, 'neg_mean_absolute_error': scorer_mae, 'neg_mean_squared_error': scorer_rmse}, \n",
    "                                  refit='r2', \n",
    "                                  n_jobs=-1)\n",
    "\n",
    "# Exécution de la recherche sur la grille des hyperparamètres\n",
    "forest_grid_search.fit(X_train, y_train['SiteEnergyUse(kBtu)'])\n",
    "\n",
    "# Score R2 MAE RMSE\n",
    "best_r2_score1 = forest_grid_search.best_score_\n",
    "best_mae_score1 = -forest_grid_search.cv_results_['mean_test_neg_mean_absolute_error'][forest_grid_search.best_index_]\n",
    "best_rmse_score1 = -forest_grid_search.cv_results_['mean_test_neg_mean_squared_error'][forest_grid_search.best_index_]\n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"Random Forest\")\n",
    "print(\"-------------------\")\n",
    "print(\"- Meilleurs hyperparamètres:\", forest_grid_search.best_params_)\n",
    "print(\"- Meilleur score R2 :\", best_r2_score1)\n",
    "print(\"- Meilleur score MAE :\", best_mae_score1)\n",
    "print(\"- Meilleur score RMSE :\", best_rmse_score1)\n",
    "print(\"- Meilleur temps d'execution:\", forest_grid_search.refit_time_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparaison avec données de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir la fonction de transformation logarithmique\n",
    "def logarithmic_transform(X): return np.log1p(X)\n",
    "\n",
    "# Pipeline de transformations\n",
    "numerical_pipeline = Pipeline(steps=[('log_transform', FunctionTransformer(func=logarithmic_transform))])\n",
    "categorical_pipeline = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "preprocessor = ColumnTransformer(transformers=[('numerical', numerical_pipeline, numerical_data),\n",
    "                                               ('categorical', categorical_pipeline, categorical_data)])\n",
    "\n",
    "# Création du pipeline du modèle Random Forest\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('random_forest', RandomForestRegressor())])\n",
    "\n",
    "# Entraînement du modèle\n",
    "pipeline.fit(X_train, y_train['SiteEnergyUse(kBtu)'])\n",
    "\n",
    "# Prédiction sur l'ensemble de test\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Calculez le coefficient de détermination R²\n",
    "r2 = r2_score(y_test['SiteEnergyUse(kBtu)'], y_pred)\n",
    "\n",
    "print(\"Coefficient de détermination R² sur les données de test :\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_data = ['Category', 'Neighborhood']\n",
    "numerical_data = ['NumberofFloors','NumberofBuildings','PropertyGFATotal','BuildingAge','GasUseRatio','ElectricityUseRatio','ParkingGFARatio','ENERGYSTARScore']\n",
    "\n",
    "X = data_bis.drop(['TotalGHGEmissions','SiteEnergyUse(kBtu)'], axis=1)\n",
    "\n",
    "y = data_bis[['TotalGHGEmissions','SiteEnergyUse(kBtu)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir la fonction de transformation logarithmique\n",
    "def logarithmic_transform(X): return np.log1p(X)\n",
    "\n",
    "# Pipeline de transformations\n",
    "numerical_pipeline = Pipeline(steps=[('log_transform', FunctionTransformer(func=logarithmic_transform))])\n",
    "categorical_pipeline = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "preprocessor = ColumnTransformer(transformers=[('numerical', numerical_pipeline, numerical_data),\n",
    "                                               ('categorical', categorical_pipeline, categorical_data)])\n",
    "\n",
    "# Pipeline de Random Forest\n",
    "forest_pipeline = Pipeline([('preprocessor', preprocessor),\n",
    "                            ('random_forest', RandomForestRegressor())])\n",
    "\n",
    "# Création des métriques de score personnalisées pour R2 MAE RMSE\n",
    "scorer_r2 = make_scorer(r2_score)\n",
    "scorer_mae = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "scorer_rmse = make_scorer(lambda y_true, y_pred: mean_squared_error(y_true, y_pred, squared=False), greater_is_better=False)\n",
    "\n",
    "# Hyperparamètres à rechercher\n",
    "forest_param_grid = {'random_forest__bootstrap': [False], 'random_forest__max_depth': [15], 'random_forest__max_features': [0.8], 'random_forest__min_samples_leaf': [1], 'random_forest__min_samples_split': [2]}\n",
    "\n",
    "forest_grid_search = GridSearchCV(forest_pipeline, \n",
    "                                  param_grid=forest_param_grid, \n",
    "                                  cv=5, \n",
    "                                  scoring={'r2': scorer_r2, 'neg_mean_absolute_error': scorer_mae, 'neg_mean_squared_error': scorer_rmse}, \n",
    "                                  refit='r2', \n",
    "                                  n_jobs=-1)\n",
    "\n",
    "# Exécution de la recherche sur la grille des hyperparamètres\n",
    "forest_grid_search.fit(X_train, y_train['SiteEnergyUse(kBtu)'])\n",
    "\n",
    "# Score R2 MAE RMSE\n",
    "best_r2_score2 = forest_grid_search.best_score_\n",
    "best_mae_score2 = -forest_grid_search.cv_results_['mean_test_neg_mean_absolute_error'][forest_grid_search.best_index_]\n",
    "best_rmse_score2 = -forest_grid_search.cv_results_['mean_test_neg_mean_squared_error'][forest_grid_search.best_index_]\n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"Random Forest\")\n",
    "print(\"-------------------\")\n",
    "print(\"- Meilleurs hyperparamètres:\", forest_grid_search.best_params_)\n",
    "print(\"- Meilleur score R2 :\", best_r2_score2)\n",
    "print(\"- Meilleur score MAE :\", best_mae_score2)\n",
    "print(\"- Meilleur score RMSE :\", best_rmse_score2)\n",
    "print(\"- Meilleur temps d'execution:\", forest_grid_search.refit_time_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparaison avec données de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir la fonction de transformation logarithmique\n",
    "def logarithmic_transform(X): return np.log1p(X)\n",
    "\n",
    "# Pipeline de transformations\n",
    "numerical_pipeline = Pipeline(steps=[('log_transform', FunctionTransformer(func=logarithmic_transform))])\n",
    "categorical_pipeline = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "preprocessor = ColumnTransformer(transformers=[('numerical', numerical_pipeline, numerical_data),\n",
    "                                               ('categorical', categorical_pipeline, categorical_data)])\n",
    "\n",
    "# Création du pipeline du modèle Random Forest\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('random_forest', RandomForestRegressor())])\n",
    "\n",
    "# Entraînement du modèle\n",
    "pipeline.fit(X_train, y_train['SiteEnergyUse(kBtu)'])\n",
    "\n",
    "# Prédiction sur l'ensemble de test\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Calculez le coefficient de détermination R²\n",
    "r2 = r2_score(y_test['SiteEnergyUse(kBtu)'], y_pred)\n",
    "\n",
    "print(\"Coefficient de détermination R² sur les données de test :\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Données à comparer\n",
    "measures_with_energystarscore = {'R2': best_r2_score1,\n",
    "                                    'MAE': best_mae_score1,\n",
    "                                    'RMSE': best_rmse_score1,\n",
    "                                    'Temps d\\'exécution': forest_grid_search.refit_time_}\n",
    "\n",
    "measures_without_energystarscore  = {'R2': best_r2_score2,\n",
    "                                'MAE': best_mae_score2,\n",
    "                                'RMSE': best_rmse_score2,\n",
    "                                'Temps d\\'exécution': forest_grid_search.refit_time_}\n",
    "\n",
    "# Création de la figure et des sous-graphiques\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.bar(['Sans Energystarscore', 'Avec Energystarscore'], [measures_without_energystarscore['R2'], measures_with_energystarscore['R2']], color=['steelblue', 'darkblue'])\n",
    "plt.title('Comparaison de R2')\n",
    "plt.ylabel('R2')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.bar(['Sans Energystarscore', 'Avec Energystarscore'], [measures_without_energystarscore['MAE'], measures_with_energystarscore['MAE']], color=['steelblue', 'darkblue'])\n",
    "plt.title('Comparaison de MAE')\n",
    "plt.ylabel('MAE')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.bar(['Sans Energystarscore', 'Avec Energystarscore'], [measures_without_energystarscore['RMSE'], measures_with_energystarscore['RMSE']], color=['steelblue', 'darkblue'])\n",
    "plt.title('Comparaison de RMSE')\n",
    "plt.ylabel('RMSE')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.bar(['Sans Energystarscore', 'Avec Energystarscore'], [measures_without_energystarscore['Temps d\\'exécution'], measures_with_energystarscore['Temps d\\'exécution']], color=['steelblue', 'darkblue'])\n",
    "plt.title('Comparaison de temps d\\'exécution')\n",
    "plt.ylabel('Temps d\\'exécution')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
